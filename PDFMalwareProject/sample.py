import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, f1_score, classification_report, confusion_matrix, roc_auc_score
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
from tqdm import tqdm

# Define the filename
filename = 'PDFMalware2022.csv'

# Load the dataset
df = pd.read_csv(filename)

# Display basic information about the dataset
print(df.info())
print(df.describe())

# Handle missing values for numeric columns
numeric_cols = df.select_dtypes(include=[np.number]).columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

# Filter out any class labeled as 2
df = df[df['Class'].isin(['Malicious', 'Benign'])]

# Convert 'Class' to a uniform type (string)
df['Class'] = df['Class'].astype(str)

# Encode target variable
le = LabelEncoder()
df['Class'] = le.fit_transform(df['Class'])

# Drop non-numeric columns for feature scaling
df_cleaned = df.drop(columns=['header', 'Fine name', 'Class'])

# Convert all columns to numeric where possible
df_cleaned = df_cleaned.apply(pd.to_numeric, errors='coerce')
df_cleaned.fillna(df_cleaned.mean(), inplace=True)

# Check if df_cleaned is empty before proceeding
if df_cleaned.empty:
    raise ValueError("The features DataFrame is empty after processing. Please check your dataset.")

# Split features and target
features = df_cleaned
target = df['Class']

# Scale features
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42, stratify=target)

# Check class distribution
print("Class distribution in training set:")
print(pd.Series(y_train).value_counts())

# Apply SMOTE to the training data
smote = SMOTE(sampling_strategy='minority')
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Hyperparameter tuning for RandomForestClassifier using GridSearchCV
rf_param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'class_weight': ['balanced', None]
}

print("Training Random Forest...")
with tqdm(total=1, desc="Random Forest") as pbar:
    try:
        rf_model = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy')
        rf_model.fit(X_resampled, y_resampled)
    except Exception as e:
        print("Error training Random Forest:", e)
    pbar.update(1)

print(f"Best parameters for Random Forest: {rf_model.best_params_}")

# Hyperparameter tuning for SVC using GridSearchCV
svm_param_grid = {
    'C': [0.1, 1.0, 10],
    'kernel': ['linear', 'rbf'],
    'class_weight': ['balanced', None]
}

print("Training SVM...")
with tqdm(total=1, desc="SVM") as pbar:
    try:
        svm_model = GridSearchCV(SVC(probability=True, random_state=42), svm_param_grid, cv=5, scoring='accuracy')
        svm_model.fit(X_resampled, y_resampled)
    except Exception as e:
        print("Error training SVM:", e)
    pbar.update(1)

print(f"Best parameters for SVM: {svm_model.best_params_}")

# Hyperparameter tuning for GradientBoostingClassifier using GridSearchCV
gb_param_grid = {
    'n_estimators': [100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7],
}

print("Training Gradient Boosting...")
with tqdm(total=1, desc="Gradient Boosting") as pbar:
    try:
        gb_model = GridSearchCV(GradientBoostingClassifier(random_state=42), gb_param_grid, cv=5, scoring='accuracy')
        gb_model.fit(X_resampled, y_resampled)
        pbar.update(1)  # Move the update inside the try block after fitting
    except Exception as e:
        print("Error training Gradient Boosting:", e)
        gb_model = None  # Set gb_model to None to avoid referencing an unfitted model

# Check if the model was fitted successfully before accessing best_params_
if gb_model is not None:
    print(f"Best parameters for Gradient Boosting: {gb_model.best_params_}")
else:
    print("Gradient Boosting model was not fitted successfully.")


# Predictions
rf_preds = rf_model.predict(X_test)
svm_preds = svm_model.predict(X_test)
gb_preds = gb_model.predict(X_test)

# Evaluate models
print("Random Forest Accuracy:", accuracy_score(y_test, rf_preds))
print("SVM Accuracy:", accuracy_score(y_test, svm_preds))
print("Gradient Boosting Accuracy:", accuracy_score(y_test, gb_preds))

print("Random Forest Precision:", precision_score(y_test, rf_preds, average='weighted'))
print("SVM Precision:", precision_score(y_test, svm_preds, average='weighted'))
print("Gradient Boosting Precision:", precision_score(y_test, gb_preds, average='weighted'))

# F1 Score
print("Random Forest F1 Score:", f1_score(y_test, rf_preds, average='weighted'))
print("SVM F1 Score:", f1_score(y_test, svm_preds, average='weighted'))
print("Gradient Boosting F1 Score:", f1_score(y_test, gb_preds, average='weighted'))

# Ensemble Model
voting_model = VotingClassifier(estimators=[
    ('rf', rf_model.best_estimator_), 
    ('svm', svm_model.best_estimator_), 
    ('gb', gb_model.best_estimator_)
], voting='soft')

print("Training Ensemble Model...")
with tqdm(total=1, desc="Ensemble Model") as pbar:
    try:
        voting_model.fit(X_resampled, y_resampled)
    except Exception as e:
        print("Error training Ensemble Model:", e)
    pbar.update(1)

# Make final predictions
final_preds = voting_model.predict(X_test)

# Display classification report
print(classification_report(y_test, final_preds))

# Confusion matrix visualization
plt.figure(figsize=(10, 7))
sns.heatmap(confusion_matrix(y_test, final_preds), annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix for Ensemble Model")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Close the plot to prevent hanging
plt.close()

# Create directory if it doesn't exist
os.makedirs('PDFMalware/models3/', exist_ok=True)

# Save models
print("Saving models...")
try:
    joblib.dump(rf_model.best_estimator_, 'PDFMalware/models3/rf_model.pkl')
    print("Random Forest model saved to 'PDFMalware/models3/rf_model.pkl'")
    
    joblib.dump(svm_model.best_estimator_, 'PDFMalware/models3/svm_model.pkl')
    print("SVM model saved to 'PDFMalware/models3/svm_model.pkl'")
    
    joblib.dump(gb_model.best_estimator_, 'PDFMalware/models3/gb_model.pkl')
    print("Gradient Boosting model saved to 'PDFMalware/models3/gb_model.pkl'")
    
    joblib.dump(voting_model, 'PDFMalware/models3/voting_model.pkl')
    print("Ensemble model saved to 'PDFMalware/models3/voting_model.pkl'")
except Exception as e:
    print("Error saving models:", e)

