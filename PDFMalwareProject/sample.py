import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, precision_score, f1_score, classification_report,
    confusion_matrix, roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score
)
from sklearn.calibration import CalibratedClassifierCV
from sklearn.feature_selection import SelectKBest, mutual_info_classif
from imblearn.over_sampling import SMOTE, ADASYN
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.pipeline import Pipeline

# Load the dataset
filename = 'PDFMalware2022.csv'
df = pd.read_csv(filename)

# Basic dataset inspection
print("Initial DataFrame Info:")
print(df.info())
print(df.describe())

# Handle missing values
numeric_cols = df.select_dtypes(include=[np.number]).columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

# Retain only 'Malicious' and 'Benign' classes
df = df[df['Class'].isin(['Malicious', 'Benign'])]

# Encode target variable
df['Class'] = LabelEncoder().fit_transform(df['Class'])  # Malicious: 1, Benign: 0

# Drop non-numeric columns and 'Class' correctly
non_numeric_cols = ['header', 'Fine name']  # Specify non-numeric columns manually if needed
df_cleaned = df.drop(columns=non_numeric_cols, errors='ignore')
df_cleaned = df_cleaned.apply(pd.to_numeric, errors='coerce')
df_cleaned.fillna(df_cleaned.mean(), inplace=True)

# Check DataFrame after cleaning
print("DataFrame Info After Cleaning:")
print(df_cleaned.info())

# Split into features and target without dropping 'Class' accidentally
features = df_cleaned.drop('Class', axis=1)
target = df_cleaned['Class']

# Scale features
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# Feature selection
selector = SelectKBest(mutual_info_classif, k='all').fit(features_scaled, target)
selected_features = selector.transform(features_scaled)

# PCA for dimensionality reduction (optional)
pca = PCA(n_components=0.95)  # Retain 95% variance
features_reduced = pca.fit_transform(selected_features)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(features_reduced, target, test_size=0.2, random_state=42, stratify=target)

# Balance classes using ADASYN (alternative to SMOTE)
adasyn = ADASYN(sampling_strategy='minority', random_state=42)
X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)

# Function to train and evaluate models
def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name):
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='f1_weighted')

    model.fit(X_train, y_train)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = (y_pred_proba > 0.85).astype(int)  # Custom threshold

    print(f"{model_name} Metrics:")
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.3f}")
    print(f"Precision: {precision_score(y_test, y_pred, average='weighted'):.3f}")
    print(f"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.3f}")
    print(f"AUC Score: {roc_auc_score(y_test, y_pred_proba):.3f}")
    print("Cross-Validation F1 Scores:", cv_scores)
    print(classification_report(y_test, y_pred))

    return model

# Define models
models = {
    "Random Forest": RandomForestClassifier(n_estimators=500, max_depth=20, min_samples_split=5, class_weight="balanced", random_state=42),
    "SVM": SVC(C=1.0, kernel='rbf', probability=True, class_weight="balanced", random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42),
    "XGBoost": XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, scale_pos_weight=10, random_state=42),
    "LightGBM": LGBMClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, class_weight="balanced", random_state=42)
}

trained_models = {}
for name, model in models.items():
    print(f"Training {name}...")
    trained_models[name] = train_and_evaluate_model(model, X_resampled, y_resampled, X_test, y_test, name)

# Ensemble model (Voting Classifier)
voting_model = VotingClassifier(estimators=[(name, model) for name, model in trained_models.items()], voting='soft', weights=[1, 1, 2, 2, 2])
voting_model.fit(X_resampled, y_resampled)

# Evaluate ensemble model
ensemble_predictions = voting_model.predict(X_test)
ensemble_proba = voting_model.predict_proba(X_test)[:, 1]

print("Ensemble Model Classification Report:")
print(classification_report(y_test, ensemble_predictions))

# Plot confusion matrix
cm = confusion_matrix(y_test, ensemble_predictions)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix for Ensemble Model")
plt.show()

# Save models
output_dir = 'PDFMalware/models18'
os.makedirs(output_dir, exist_ok=True)
for name, model in trained_models.items():
    joblib.dump(model, os.path.join(output_dir, f"{name.lower().replace(' ', '_')}_model.pkl"))
joblib.dump(voting_model, os.path.join(output_dir, "ensemble_model.pkl"))

print("All models have been saved successfully!")

