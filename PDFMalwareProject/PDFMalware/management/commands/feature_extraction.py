import sys
import pandas as pd
from pdfminer.high_level import extract_text
from pdfminer.pdfparser import PDFParser
from pdfminer.pdfdocument import PDFDocument
from pdfminer.pdfpage import PDFPage
import os
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def count_keyword_occurrences(content, keywords):
    return {keyword: content.count(keyword) for keyword in keywords}

def extract_features_from_pdf(pdf_path):
    features = {
        'pdfsize': 0,
        'isEncrypted': 0,
        'pages': 0,
        'metadata size': 0,
        'title characters': 0,
        'text': 0,
        'embedded files': 0, 'images': 0, 'header': 0, 'obj': 0,
        'endobj': 0, 'stream': 0, 'endstream': 0, 'xref': 0, 'trailer': 0,
        'startxref': 0, 'encrypt': 0, 'ObjStm': 0, 'JS': 0,
        'Javascript': 0, 'AA': 0, 'OpenAction': 0, 'Acroform': 0, 'JBIG2Decode': 0,
        'RichMedia': 0, 'launch': 0, 'EmbeddedFile': 0, 'XFA': 0, 'Colors': 0
    }
    
    try:
        with open(pdf_path, 'rb') as file:
            parser = PDFParser(file)
            document = PDFDocument(parser)
            
            # Basic properties
            features['pdfsize'] = os.path.getsize(pdf_path)
            features['isEncrypted'] = int(document.is_encrypted)
            features['pages'] = sum(1 for _ in PDFPage.create_pages(document))  # Count number of pages
            
            # Metadata
            metadata = document.info[0] if document.info else {}
            features['metadata size'] = sum(len(str(v)) for v in metadata.values())
            features['title characters'] = len(metadata.get('Title', '').encode('utf-8'))
            
            # Extract text content
            pdf_text = extract_text(pdf_path)
            features['text'] = len(pdf_text)  # Character count of the text
            
            # Analyze raw PDF content
            file.seek(0)
            raw_content = file.read().decode(errors='ignore')
            
            # Keywords to search within the raw content
            keywords = [
                'obj', 'endobj', 'stream', 'endstream', 'xref', 'trailer', 'startxref', 'Encrypt',
                '/EmbeddedFile', '/Image', '/JS', '/JavaScript', '/AA', '/OpenAction', '/AcroForm',
                '/JBIG2Decode', '/RichMedia', '/Launch', '/XFA', '/ObjStm'
            ]
            keyword_counts = count_keyword_occurrences(raw_content, keywords)
            features.update(keyword_counts)

            # Detect color keywords (basic example, can be refined)
            features['Colors'] = raw_content.lower().count('rgb') + raw_content.lower().count('cmyk')

    except Exception as e:
        logging.error(f"Error processing PDF file {pdf_path}: {e}")
        raise

    return features

def main():
    if len(sys.argv) != 3:
        print("Usage: python feature_extraction.py <input_pdf_path> <output_csv_path>")
        return

    input_pdf_path = sys.argv[1]
    output_csv_path = sys.argv[2]

    try:
        # Extract features from the PDF
        features = extract_features_from_pdf(input_pdf_path)

        # Convert features to DataFrame and save to CSV
        features_df = pd.DataFrame([features])  # Wrap in a list to create a DataFrame
        features_df.to_csv(output_csv_path, index=False)
        logging.info(f"Features extracted and saved to {output_csv_path}")
        
    except Exception as e:
        logging.error(f"Failed to extract features: {e}")

if __name__ == "__main__":
    main()

