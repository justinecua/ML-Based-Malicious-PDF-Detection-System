import os
import io
import subprocess
import joblib
import numpy as np
import pandas as pd
from django.conf import settings
from django.shortcuts import render
from django.core.files.storage import FileSystemStorage
from PyPDF2 import PdfReader
from pdfminer.high_level import extract_text
from PIL import Image
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load models and scaler at the start to avoid reloading for each request
rf_model = joblib.load('PDFMalware/models2/rf_model.pkl')
svm_model = joblib.load('PDFMalware/models2/svm_model.pkl')
gb_model = joblib.load('PDFMalware/models2/gb_model.pkl')
scaler = joblib.load('PDFMalware/models2/scaler.pkl')
le = joblib.load('PDFMalware/models2/label_encoder.pkl')

def homepage(request):
    if request.method == 'POST' and request.FILES.get('pdf_file'):
        uploaded_file = request.FILES['pdf_file']
        file_path = handle_file_upload(uploaded_file)  # Your file handling logic
        logger.info(f'Uploaded file path: {file_path}')

        # Analyze the PDF and get results
        analysis_result = analyze_pdf(file_path)  # Replace with your analysis function
        logger.info(f'Analysis result: {analysis_result}')

        # Prepare the context for rendering
        context = {
            'uploaded_file_name': uploaded_file.name,
            'analysis_result': analysis_result,
        }
        return render(request, 'home.html', context)

    return render(request, 'home.html')

def handle_file_upload(uploaded_file):
    """Handle file upload and save it to the filesystem."""
    uploads_directory = os.path.join('uploads')  # Ensure this path is correct
    fs = FileSystemStorage(location=uploads_directory)
    filename = fs.save(uploaded_file.name, uploaded_file)
    return os.path.join(fs.location, filename)

def extract_images_from_pdf(pdf_path):
    """Extract images from a PDF file and save them as PNG files."""
    images = []
    with open(pdf_path, 'rb') as f:
        reader = PdfReader(f)
        for page_number, page in enumerate(reader.pages):
            if '/XObject' in page:
                xObject = page['/XObject'].get_object()
                for obj in xObject:
                    if xObject[obj]['/Subtype'] == '/Image':
                        image_data = xObject[obj].get_data()
                        pil_image = Image.open(io.BytesIO(image_data))
                        
                        if pil_image.mode not in ['RGB', 'RGBA']:
                            pil_image = pil_image.convert('RGB')
                        
                        img_path = os.path.join('uploads', f'image_page_{page_number}.png')
                        try:
                            pil_image.save(img_path, format='PNG')
                            images.append(img_path)
                        except OSError as e:
                            logger.error(f"Error saving image: {e}")
    
    logger.info(f"Extracted images from {pdf_path}: {images}")
    return images

def extract_features_from_pdf(pdf_path):
    """Extract features from a PDF file and return them as a DataFrame."""
    features = {
        'pdfsize': 0,
        'metadata size': 0,
        'pages': 0,
        'xref Length': 0,
        'title characters': 0,
        'isEncrypted': 0,
        'embedded files': 0,
        'images': 0,
        'text': 0,
        'obj': 0,
        'endobj': 0,
        'stream': 0,
        'endstream': 0,
        'xref': 0,
        'trailer': 0,
        'startxref': 0,
        'pageno': 0,
        'encrypt': 0,
        'ObjStm': 0,
        'JS': 0,
        'Javascript': 0,
        'AA': 0,
        'OpenAction': 0,
        'Acroform': 0,
        'JBIG2Decode': 0,
        'RichMedia': 0,
        'launch': 0,
        'EmbeddedFile': 0,
        'XFA': 0,
        'Colors': 0,
    }

    with open(pdf_path, 'rb') as f:
        features['pdfsize'] = f.tell()
        reader = PdfReader(f)
        features['isEncrypted'] = int(reader.is_encrypted)
        features['pages'] = len(reader.pages)

        metadata = reader.metadata or {}
        features['title characters'] = len(metadata.get('/Title', ''))

        embedded_files_count = 0
        if "/EmbeddedFiles" in reader.trailer:
            embedded_files_count = len(reader.trailer["/EmbeddedFiles"])

        features['embedded files'] = embedded_files_count

        images = extract_images_from_pdf(pdf_path)
        features['images'] = len(images)

        text = extract_text(pdf_path)
        features['text'] = len(text)

        features['obj'] = len(reader.pages)
        features['endobj'] = len(reader.pages)
        features['stream'] = 0
        features['endstream'] = 0
        features['xref'] = 0
        features['trailer'] = 0
        features['startxref'] = 0
        features['pageno'] = 0
        features['encrypt'] = 1 if features['isEncrypted'] else 0
        features['ObjStm'] = 0
        features['JS'] = 0
        features['Javascript'] = 0
        features['AA'] = 0
        features['OpenAction'] = 0
        features['Acroform'] = 0
        features['JBIG2Decode'] = 0
        features['RichMedia'] = 0
        features['launch'] = 0
        features['EmbeddedFile'] = embedded_files_count
        features['XFA'] = 0
        features['Colors'] = 0

    features_df = pd.DataFrame([features])
    logger.info(f"Extracted features from {pdf_path}: {features_df}")
    return features_df

def preprocess_and_scale_pdf(pdf_path):
    """Extract features and scale them for prediction."""
    features_df = extract_features_from_pdf(pdf_path)
    features_array = features_df.values
    features_scaled = scaler.transform(features_array)
    logger.info(f"Scaled features for {pdf_path}: {features_scaled}")
    return features_scaled

@csrf_exempt
def predict(request):
    if request.method == 'POST' and request.FILES.get('pdf_file'):
        pdf_file = request.FILES['pdf_file']
        uploads_directory = os.path.join('uploads')
        fs = FileSystemStorage(location=uploads_directory)
        filename = fs.save(pdf_file.name, pdf_file)
        uploaded_file_path = os.path.join(fs.location, filename)

        uploads_dir = os.path.abspath(fs.location)
        logger.info(f"Uploaded file path: {uploaded_file_path}")

        try:
            result = subprocess.check_output(
                ['docker', 'run', '--rm', '-v', f"{uploads_dir}:/app/uploads", 'pdf_analyzer', 'python', '/app/analyze_pdf.py', f'/app/uploads/{filename}'],
                stderr=subprocess.STDOUT
            ).decode('utf-8')
            logger.info(f"Docker analysis result: {result}")
        except subprocess.CalledProcessError as e:
            result = f"An error occurred: {e.output.decode('utf-8')}"
            logger.error(f"Docker analysis error: {result}")

        features_scaled = preprocess_and_scale_pdf(uploaded_file_path)

        rf_pred = rf_model.predict(features_scaled)
        svm_pred = svm_model.predict(features_scaled)
        gb_pred = gb_model.predict(features_scaled)

        logger.info(f"Predictions - RF: {rf_pred[0]}, SVM: {svm_pred[0]}, GB: {gb_pred[0]}")

        predictions = [rf_pred[0], svm_pred[0], gb_pred[0]]
        final_prediction = max(set(predictions), key=predictions.count)
        final_result = le.inverse_transform([final_prediction])[0]
        logger.info(f"Final prediction: {final_result}")

        full_result = f"Scan Result:\n{result}\n\nPrediction: PDF is classified as: {final_result}"

        return render(request, 'home.html', {'result': full_result})

    return render(request, 'home.html')

